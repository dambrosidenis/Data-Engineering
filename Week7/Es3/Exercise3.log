Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 2.4.6
      /_/
         
Using Scala version 2.11.12 (OpenJDK 64-Bit Server VM, Java 1.8.0_392)
Type in expressions to have them evaluated.
Type :help for more information.

scala> val df1 = spark.read.json("hdfs://0.0.0.0:9000/input/people.json")
df1: org.apache.spark.sql.DataFrame = [age: bigint, name: string]              

scala> val df2 = spark.read.json("hdfs://0.0.0.0:9000/input/addresses.json")
df2: org.apache.spark.sql.DataFrame = [address: string, city: string ... 1 more field]

scala> df1.show()
+----+-------+
| age|   name|
+----+-------+
|null|Michael|
|  30|   Andy|
|  19| Justin|
+----+-------+


scala> df2.show()
+----------------+---------+------+
|         address|     city|  name|
+----------------+---------+------+
|   Main Street 2|   Boston|George|
|Secondary Road 1|   London|  Andy|
|  Round Square 0|   Madrid|Justin|
|    Abbey Road 9|   London|Hannah|
|    Penny Lane 3|Liverpool|  Leah|
+----------------+---------+------+


scala> df1.join(df2, df1("name") === df2("name"), "inner").show()
+---+------+----------------+------+------+
|age|  name|         address|  city|  name|
+---+------+----------------+------+------+
| 30|  Andy|Secondary Road 1|London|  Andy|
| 19|Justin|  Round Square 0|Madrid|Justin|
+---+------+----------------+------+------+


scala> df1.join(df2, df1("name") === df2("name"), "outer").show()
+----+-------+----------------+---------+------+                                
| age|   name|         address|     city|  name|
+----+-------+----------------+---------+------+
|null|   null|    Abbey Road 9|   London|Hannah|
|null|Michael|            null|     null|  null|
|null|   null|    Penny Lane 3|Liverpool|  Leah|
|null|   null|   Main Street 2|   Boston|George|
|  30|   Andy|Secondary Road 1|   London|  Andy|
|  19| Justin|  Round Square 0|   Madrid|Justin|
+----+-------+----------------+---------+------+


scala> df1.createOrReplaceTempView("people")

scala> df2.createOrReplaceTempView("addresses")

scala> val sqlDF = spark.sql("SELECT * FROM people JOIN addresses ON people.name = addresses.name")
23/12/13 05:43:42 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
sqlDF: org.apache.spark.sql.DataFrame = [age: bigint, name: string ... 3 more fields]

scala> sqlDF.show()
+---+------+----------------+------+------+
|age|  name|         address|  city|  name|
+---+------+----------------+------+------+
| 30|  Andy|Secondary Road 1|London|  Andy|
| 19|Justin|  Round Square 0|Madrid|Justin|
+---+------+----------------+------+------+


scala> val sqlDF_ = spark.sql("SELECT * FROM people FULL OUTER JOIN addresses ON people.name = addresses.name")
sqlDF_: org.apache.spark.sql.DataFrame = [age: bigint, name: string ... 3 more fields]

scala> sqlDF_.show()
+----+-------+----------------+---------+------+                                
| age|   name|         address|     city|  name|
+----+-------+----------------+---------+------+
|null|   null|    Abbey Road 9|   London|Hannah|
|null|Michael|            null|     null|  null|
|null|   null|    Penny Lane 3|Liverpool|  Leah|
|null|   null|   Main Street 2|   Boston|George|
|  30|   Andy|Secondary Road 1|   London|  Andy|
|  19| Justin|  Round Square 0|   Madrid|Justin|
+----+-------+----------------+---------+------+